Basic Concepts in ZhuSuan
=========================

.. _dist-and-stochastic:

Distribution and StochasticTensor
---------------------------------

Probabilistic distributions are key components for building directed graphical
models (Bayesian Networks). ZhuSuan provides two layers of abstraction
for them: :class:`~zhusuan.distributions.base.Distribution` and
:class:`~zhusuan.model.base.StochasticTensor`, which may be
a little confusing for beginners. We make their definitions and connections
clear here.

Distribution
^^^^^^^^^^^^

The :class:`~zhusuan.distributions.base.Distribution` class is the base class
for various probabilistic distributions which support batch inputs, generating
batches of samples and evaluate probabilities at batches of given values.

The list of all available distributions can be found on these pages:

* :mod:`univariate distributions <zhusuan.distributions.univariate>`
* :mod:`multivariate distributions <zhusuan.distributions.multivariate>`

These distributions can be accessed from ZhuSuan by (for example, a univariate
Normal distribution)::

    >>> import zhusuan as zs
    >>> a = zs.distributions.Normal(mean=0., logstd=0.)

The typical input shape for a :class:`~zhusuan.distributions.base.Distribution`
is like ``batch_shape + input_shape``. where ``input_shape`` represents the
shape of a non-batch input parameter;
:attr:`~.Distribution.batch_shape` represents how many independent inputs are
fed into the distribution. In general, distributions support broadcasting for
inputs.

Samples can be generated by calling
:meth:`~zhusuan.distributions.base.Distribution.sample` method of distribution
objects. The shape is ``([n_samples] + )batch_shape + value_shape``.
The first additional axis is omitted only when passed `n_samples` is None
(by default), in which case one sample is generated. ``value_shape`` is the
non-batch value shape of the distribution. For a univariate distribution,
its ``value_shape`` is [].

Example of univariate distributions
(:class:`~zhusuan.distributions.univariate.Normal`)::

    >>> import tensorflow as tf
    >>> _ = tf.InteractiveSession()

    >>> b = zs.distributions.Normal([[-1., 1.], [0., -2.]], [0., 1.])

    >>> b.batch_shape.eval()
    array([2, 2], dtype=int32)

    >>> b.value_shape.eval()
    array([], dtype=int32)

    >>> tf.shape(b.sample()).eval()
    array([2, 2], dtype=int32)

    >>> tf.shape(b.sample(1)).eval()
    array([1, 2, 2], dtype=int32)

    >>> tf.shape(b.sample(10)).eval()
    array([10,  2,  2], dtype=int32)

Example of multivariate distributions
(:class:`~zhusuan.distributions.multivariate.OnehotCategorical`)::

    >>> c = zs.distributions.OnehotCategorical([[0., 1., -1.],
    ...                                         [2., 3., 4.]])

    >>> c.batch_shape.eval()
    array([2], dtype=int32)

    >>> c.value_shape.eval()
    array([3], dtype=int32)

    >>> tf.shape(c.sample()).eval()
    array([2, 3], dtype=int32)

    >>> tf.shape(c.sample(1)).eval()
    array([1, 2, 3], dtype=int32)

    >>> tf.shape(c.sample(10)).eval()
    array([10,  2,  3], dtype=int32)

There are cases where a batch of random variables are grouped into a
single event so that their probabilities can be computed together. This
is achieved by setting `group_event_ndims` argument, which defaults to 0.
The last `group_event_ndims` number of axes in
:attr:`~.Distribution.batch_shape` are grouped into a single event.
For example, ``Normal(..., group_event_ndims=1)`` will
set the last axis of its :attr:`~.Distribution.batch_shape` to a single event,
i.e., a multivariate Normal with identity covariance matrix.

Log probability density (mass) function can be evaluated by passing given
values to :meth:`~zhusuan.distributions.base.Distribution.log_prob` method of
distribution objects.
In that case, the given Tensor should be
broadcastable to shape ``(... + )batch_shape + value_shape``. The returned
Tensor has shape ``(... + )batch_shape[:-group_event_ndims]``. For example::

    >>> d = zs.distributions.Normal([[-1., 1.], [0., -2.]], 0.,
    ...                             group_event_ndims=1)

    >>> d.log_prob(0.).eval()
    array([-2.83787704, -3.83787727], dtype=float32)

    >>> e = zs.distributions.Normal(tf.zeros([2, 1, 3]), 0.,
    ...                             group_event_ndims=2)

    >>> tf.shape(e.log_prob(tf.zeros([5, 1, 1, 3]))).eval()
    array([5, 2], dtype=int32)

StochasticTensor
^^^^^^^^^^^^^^^^

While :class:`~zhusuan.distributions.base.Distribution` provides the basic
functionality for probabilistic distributions. Directly building computation
graph with them is still painful because they are not aware of any inner
reusability as stochastic nodes in Bayesian Networks: Once you have sampled
from a distribution, there is no way to reuse the downroot graph when you
want to observe it.

To address this challenge, ZhuSuan provides another abstraction built upon
distributions. That's :class:`~zhusuan.model.base.StochasticTensor`. For all
distributions available in :mod:`zhusuan.distributions` there is a
corresponding :class:`~zhusuan.model.base.StochasticTensor`, which can be
accessed by ``zs.Normal`` (for example, a univariate
:class:`~zhusuan.model.stochastic.Normal` StochasticTensor).
Their list is on :mod:`this page <zhusuan.model.stochastic>`.

.. Note::

    Use ``zs.Normal`` when you want
    :class:`~zhusuan.model.base.StochasticTensor` and use
    ``zs.distributions.Normal`` when you want
    :class:`~zhusuan.distributions.base.Distribution`.

:class:`~zhusuan.model.base.StochasticTensor` can only be constructed under
:class:`~zhusuan.model.base.BayesianNet` context.
Their instances are Tensor-like, which enables transparent building of Bayesian
Networks using tensorflow primitives. See the :ref:`bayesian-net` section for
examples of usage.

.. _bayesian-net:

BayesianNet
-----------



.. bibliography:: refs.bib
    :style: unsrtalpha
    :keyprefix: concepts-
